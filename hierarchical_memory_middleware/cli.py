"""Consolidated CLI interface for hierarchical memory middleware with MCP integration."""

import asyncio
import hashlib
import json
import logging
import os
import signal
import sys
import tempfile
import time
from datetime import datetime
from pathlib import Path
from typing import Optional, Tuple

import typer

# Note: We use standard input() instead of prompt_toolkit because
# prompt_toolkit's sync prompt conflicts with asyncio event loops
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.text import Text
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.markdown import Markdown
from rich.status import Status
from rich.markup import escape as rich_escape

from .config import Config
from .middleware import create_conversation_manager, ToolCallEvent, ToolResultEvent
from .middleware.conversation_manager import HierarchicalConversationManager
from .middleware.claude_agent_sdk_manager import ClaudeAgentSDKConversationManager
from .models import CompressionLevel, NodeType
from .mcp_manager import SimpleMCPManager
from .model_manager import ModelManager

# Logging will be configured by the CLI callback (setup_cli_logging)
logger = logging.getLogger(__name__)

app = typer.Typer(
    help="Hierarchical Memory Middleware CLI - Advanced conversational AI with hierarchical memory",
    rich_markup_mode="rich",
)
console = Console()

# Directory for storing large pasted content (temp files for multiline input)
PASTE_STORAGE_DIR = Path(tempfile.gettempdir()) / "hmm_paste_storage"

# Thresholds for large paste handling
LARGE_PASTE_THRESHOLD = 5000  # characters
LARGE_PASTE_LINES_THRESHOLD = 8  # lines


def format_edit_diff(old_string: str, new_string: str, file_path: str, max_lines: int = 10) -> str:
    """Format an Edit tool call as a diff-style display.

    Shows full old/new lines with word-level highlighting, inspired by GitHub's
    split diff view. Full lines are displayed with -/+ prefixes, but only the
    specific changed words get highlighted with colored backgrounds.

    Args:
        old_string: The text being replaced
        new_string: The replacement text
        file_path: The file being edited
        max_lines: Maximum lines to show

    Returns:
        Formatted string for Rich console
    """
    import difflib

    def truncate_lines(text: str, max_lines: int) -> tuple[str, int]:
        """Truncate text to max_lines, return (truncated_text, remaining_count)."""
        lines = text.split('\n')
        if len(lines) <= max_lines:
            return text, 0
        return '\n'.join(lines[:max_lines]), len(lines) - max_lines

    # Build the output
    output_parts = []
    output_parts.append(f"    [dim]ğŸ“ {file_path}[/dim]")

    # Get line-by-line diff
    old_lines = old_string.split('\n')
    new_lines = new_string.split('\n')

    # Truncate if needed
    total_lines = max(len(old_lines), len(new_lines))
    truncated = total_lines > max_lines
    if truncated:
        old_lines = old_lines[:max_lines]
        new_lines = new_lines[:max_lines]

    # Use SequenceMatcher for line-level diff
    matcher = difflib.SequenceMatcher(None, old_lines, new_lines)

    for tag, i1, i2, j1, j2 in matcher.get_opcodes():
        if tag == 'equal':
            # Unchanged lines - show dimmed
            for line in old_lines[i1:i2]:
                escaped = rich_escape(line) if line else " "
                output_parts.append(f"    [dim]  {escaped}[/dim]")
        elif tag == 'replace':
            # Changed lines - show full old/new lines but highlight only changed words
            for old_line, new_line in zip(old_lines[i1:i2], new_lines[j1:j2]):
                # Word-level diff within the line
                old_words = old_line.split()
                new_words = new_line.split()
                word_matcher = difflib.SequenceMatcher(None, old_words, new_words)

                # Build old line with changed words highlighted
                old_parts = []
                for wtag, wi1, wi2, wj1, wj2 in word_matcher.get_opcodes():
                    if wtag == 'equal':
                        for word in old_words[wi1:wi2]:
                            old_parts.append(rich_escape(word))
                    elif wtag in ('replace', 'delete'):
                        for word in old_words[wi1:wi2]:
                            old_parts.append(f"[white on #4a1515]{rich_escape(word)}[/white on #4a1515]")
                    # 'insert' doesn't affect old line

                # Build new line with changed words highlighted
                new_parts = []
                for wtag, wi1, wi2, wj1, wj2 in word_matcher.get_opcodes():
                    if wtag == 'equal':
                        for word in new_words[wj1:wj2]:
                            new_parts.append(rich_escape(word))
                    elif wtag in ('replace', 'insert'):
                        for word in new_words[wj1:wj2]:
                            new_parts.append(f"[white on #1a4a1a]{rich_escape(word)}[/white on #1a4a1a]")
                    # 'delete' doesn't affect new line

                output_parts.append(f"    [#cc6666]- {' '.join(old_parts)}[/#cc6666]")
                output_parts.append(f"    [#66cc66]+ {' '.join(new_parts)}[/#66cc66]")

            # Handle unequal line counts in replace
            extra_old = old_lines[i1 + min(i2-i1, j2-j1):i2]
            extra_new = new_lines[j1 + min(i2-i1, j2-j1):j2]
            for line in extra_old:
                escaped = rich_escape(line) if line else " "
                output_parts.append(f"    [#cc6666]- [white on #4a1515]{escaped}[/white on #4a1515][/#cc6666]")
            for line in extra_new:
                escaped = rich_escape(line) if line else " "
                output_parts.append(f"    [#66cc66]+ [white on #1a4a1a]{escaped}[/white on #1a4a1a][/#66cc66]")
        elif tag == 'delete':
            # Removed lines - whole line is highlighted
            for line in old_lines[i1:i2]:
                escaped = rich_escape(line) if line else " "
                output_parts.append(f"    [#cc6666]- [white on #4a1515]{escaped}[/white on #4a1515][/#cc6666]")
        elif tag == 'insert':
            # Added lines - whole line is highlighted
            for line in new_lines[j1:j2]:
                escaped = rich_escape(line) if line else " "
                output_parts.append(f"    [#66cc66]+ [white on #1a4a1a]{escaped}[/white on #1a4a1a][/#66cc66]")

    if truncated:
        remaining = total_lines - max_lines
        output_parts.append(f"    [dim]  ... ({remaining} more lines)[/dim]")

    return '\n'.join(output_parts)


def sanitize_input(text: str) -> str:
    """Sanitize input text to remove problematic characters that break Rich markup.

    This handles:
    - Null bytes and other control characters (except newlines/tabs)
    - ANSI escape sequences (terminal color codes, etc.)
    """
    import re

    if not text:
        return text

    # First, remove ANSI escape sequences (e.g., \x1b[31m for colors)
    # This regex matches: ESC followed by [ then any params and a letter
    ansi_pattern = re.compile(
        r"\x1b\[[0-9;]*[a-zA-Z]|\x1b\][^\x07]*\x07|\x1b[PX^_][^\x1b]*\x1b\\"
    )
    sanitized = ansi_pattern.sub("", text)

    # Remove null bytes and other problematic control characters
    # Keep: \n (10), \r (13), \t (9)
    sanitized = "".join(
        char for char in sanitized if ord(char) >= 32 or char in "\n\r\t"
    )

    return sanitized


def get_robust_input(prompt_str: str = "ğŸ‘¤ You") -> str:
    """Get user input with robust handling for multiline pastes.

    Uses a multi-line input mode where:
    - Single line typed + Enter: sends immediately (auto-detected via select())
    - Paste with newlines: captures all, shows count, single Enter to send
    - Manual multi-line: type, Enter, type more, Enter on empty line to send

    Returns the sanitized input text.
    """
    import select
    import sys

    def has_pending_input(timeout: float = 0.05) -> bool:
        """Check if there's more input waiting in stdin."""
        try:
            readable, _, _ = select.select([sys.stdin], [], [], timeout)
            return bool(readable)
        except (ValueError, OSError, AttributeError):
            return False

    try:
        # Print the prompt
        console.print(f"[bold blue]{prompt_str}:[/bold blue] [dim](Enter to send)[/dim]")
        console.print("> ", end="", highlight=False)
        sys.stdout.flush()

        lines = []
        showed_paste_message = False  # True = we've shown the "(N lines)" message

        DEBUG = os.environ.get("DEBUG_INPUT", "0") == "1"

        while True:
            try:
                line = input()

                # Check if more input is immediately available (paste detection)
                more_coming = has_pending_input(0.05)

                if DEBUG:
                    print(f"DEBUG >>> line={repr(line)[:60]}, more_coming={more_coming}, lines={len(lines)}, showed_msg={showed_paste_message}")

                if more_coming:
                    # More input waiting - we're in a paste, keep reading
                    if line:  # Don't add empty lines during paste
                        lines.append(line)
                    continue

                # No more input immediately pending

                if not lines:
                    # No lines accumulated yet
                    if line:
                        # First non-empty line with nothing pending = single line, send immediately
                        lines.append(line)
                        break
                    else:
                        # Empty first line - just re-prompt
                        console.print("> ", end="", highlight=False)
                        sys.stdout.flush()
                        continue

                # We have accumulated lines

                if not line:
                    # Empty line after accumulated content
                    if showed_paste_message:
                        # User pressed Enter after seeing the message - send!
                        if DEBUG:
                            print(f"DEBUG >>> User confirmed, BREAKING with {len(lines)} lines")
                        break
                    else:
                        # This empty line is the trailing newline from the paste
                        # Show message and wait for ONE more Enter
                        console.print(f"[dim]({len(lines)} lines) Press Enter to send, or keep typing[/dim]")
                        console.print("... ", end="", highlight=False)
                        sys.stdout.flush()
                        showed_paste_message = True
                        continue
                else:
                    # User typed/pasted more content after the paste
                    lines.append(line)
                    # Reset - they might paste more
                    showed_paste_message = False
                    # Check if more coming
                    if has_pending_input(0.1):
                        continue
                    # No more coming - show updated count
                    console.print(f"[dim]({len(lines)} lines) Press Enter to send, or keep typing[/dim]")
                    console.print("... ", end="", highlight=False)
                    sys.stdout.flush()
                    showed_paste_message = True
                    continue

            except EOFError:
                # Ctrl+D pressed - treat same as empty prompt (exit)
                raise KeyboardInterrupt()

        result = "\n".join(lines)
        return sanitize_input(result.strip())

    except EOFError:
        # Ctrl+D on completely empty prompt
        raise KeyboardInterrupt()
    except KeyboardInterrupt:
        raise


def store_large_paste(content: str, conversation_id: str) -> Tuple[str, str]:
    """Store large pasted content and return (reference_id, preview).

    Returns:
        Tuple of (reference_id, preview_text)
    """
    # Create storage directory if needed
    PASTE_STORAGE_DIR.mkdir(parents=True, exist_ok=True)

    # Generate a short hash-based reference ID
    content_hash = hashlib.sha256(content.encode()).hexdigest()[:8]
    timestamp = int(time.time())
    reference_id = f"paste_{timestamp}_{content_hash}"

    # Store the content
    paste_file = PASTE_STORAGE_DIR / f"{reference_id}.txt"
    paste_file.write_text(content, encoding="utf-8")

    # Create metadata
    meta_file = PASTE_STORAGE_DIR / f"{reference_id}.meta.json"
    lines = content.split("\n")
    meta = {
        "reference_id": reference_id,
        "conversation_id": conversation_id,
        "timestamp": timestamp,
        "char_count": len(content),
        "line_count": len(lines),
        "first_line": lines[0][:100] if lines else "",
        "stored_path": str(paste_file),
    }
    meta_file.write_text(json.dumps(meta, indent=2), encoding="utf-8")

    # Generate preview (first and last few lines)
    if len(lines) <= 6:
        preview = content[:500]
    else:
        first_lines = "\n".join(lines[:3])
        last_lines = "\n".join(lines[-2:])
        preview = f"{first_lines}\n... ({len(lines) - 5} more lines) ...\n{last_lines}"
        if len(preview) > 500:
            preview = preview[:500] + "..."

    return reference_id, preview


def get_stored_paste(reference_id: str) -> Optional[str]:
    """Retrieve stored paste content by reference ID."""
    paste_file = PASTE_STORAGE_DIR / f"{reference_id}.txt"
    if paste_file.exists():
        return paste_file.read_text(encoding="utf-8")
    return None


def is_large_paste(text: str) -> bool:
    """Check if text qualifies as a large paste."""
    return (
        len(text) > LARGE_PASTE_THRESHOLD
        or text.count("\n") > LARGE_PASTE_LINES_THRESHOLD
    )


def handle_user_input(
    conversation_id: str, compact_large_pastes: bool = True
) -> Tuple[str, bool]:
    """Get user input with full handling for large pastes.

    Args:
        conversation_id: Current conversation ID (for paste storage)
        compact_large_pastes: If True, store large pastes and return reference

    Returns:
        Tuple of (processed_input, was_compacted)
    """
    raw_input = get_robust_input()

    if not raw_input:
        return "", False

    # Check if this is a large paste that should be compacted
    if compact_large_pastes and is_large_paste(raw_input):
        reference_id, preview = store_large_paste(raw_input, conversation_id)

        # Show user what happened
        lines = raw_input.split("\n")
        console.print(
            f"\n[dim]ğŸ“‹ Large paste detected ({len(raw_input):,} chars, {len(lines)} lines)[/dim]"
        )
        console.print(f"[dim]   Stored as: {reference_id}[/dim]")
        console.print(f"[dim]   Preview:[/dim]")
        for line in preview.split("\n")[:5]:
            console.print(
                f"[dim]   â”‚ {rich_escape(line[:80])}{'...' if len(line) > 80 else ''}[/dim]"
            )
        if len(preview.split("\n")) > 5:
            console.print(f"[dim]   â”‚ ...[/dim]")
        console.print()

        # Return a message that includes the full content but with context
        # The AI will see the full paste but we've stored a reference for the UI
        return raw_input, True

    return raw_input, False


@app.callback()
def setup_cli_logging(
    debug: bool = typer.Option(
        False,
        "--debug",
        help="Enable debug logging for all commands",
    ),
):
    """Setup logging for all CLI commands."""
    config = Config.from_env()
    config.setup_cli_logging()
    if debug:
        logging.getLogger().setLevel(logging.DEBUG)


def check_mcp_server_running(mcp_url: str) -> bool:
    """Check if MCP server is running by sending an initialization request."""
    try:
        import requests
        import json

        # Add proper Accept header for MCP Streamable HTTP transport
        headers = {
            "Accept": "application/json, text/event-stream",
            "Content-Type": "application/json",
        }

        # Send MCP initialization request
        init_request = {
            "jsonrpc": "2.0",
            "id": "test-init",
            "method": "initialize",
            "params": {"protocolVersion": "2024-11-05", "capabilities": {}},
        }

        response = requests.post(mcp_url, headers=headers, json=init_request, timeout=2)
        return response.status_code == 200
    except Exception:
        return False


async def resolve_conversation_id(partial_id: str, db_path: str) -> str:
    """Resolve a partial conversation ID to a full ID, Docker-style."""
    try:
        from .storage import DuckDBStorage

        storage = DuckDBStorage(db_path)
        conversations = await storage.get_conversation_list()

        # Find conversations that start with the partial ID
        matches = [conv for conv in conversations if conv["id"].startswith(partial_id)]

        if len(matches) == 0:
            raise ValueError(
                f"No conversation found with ID starting with '{partial_id}'"
            )
        elif len(matches) == 1:
            return matches[0]["id"]
        else:
            # Multiple matches - show ambiguous error
            match_ids = [conv["id"][:12] + "..." for conv in matches]
            raise ValueError(
                f"Ambiguous conversation ID '{partial_id}'. Matches: {', '.join(match_ids)}"
            )
    except Exception as e:
        raise ValueError(f"Error resolving conversation ID: {e}")


async def resolve_conversation_name(name: str, db_path: str) -> str:
    """Resolve a conversation name to its full ID."""
    try:
        from .storage import DuckDBStorage

        storage = DuckDBStorage(db_path)
        conversations = await storage.get_conversation_list()

        # Find conversations that match the name
        matches = [conv for conv in conversations if conv.get("name") == name]

        if len(matches) == 0:
            raise ValueError(f"No conversation found with name '{name}'")
        elif len(matches) == 1:
            return matches[0]["id"]
        else:
            # Multiple matches - should not happen due to unique constraints
            raise ValueError(f"Multiple conversations found with name '{name}'")
    except Exception as e:
        raise ValueError(f"Error resolving conversation name: {e}")


async def resolve_conversation_identifier(identifier: str, db_path: str) -> str:
    """Resolve a conversation identifier (ID, partial ID, or name) to full ID."""
    # First try as partial ID
    try:
        return await resolve_conversation_id(identifier, db_path)
    except ValueError:
        pass

    # Then try as name
    try:
        return await resolve_conversation_name(identifier, db_path)
    except ValueError:
        pass

    # If neither works, raise an error
    raise ValueError(f"No conversation found with identifier '{identifier}'")


async def save_conversation_to_json(manager, conversation_id: str, export_dir: str):
    """Save conversation to JSON files for real-time viewing."""
    try:
        # Get all conversation nodes
        all_nodes = await manager.storage.get_conversation_nodes(conversation_id)

        # Save full conversation
        conversation_json_path = os.path.join(export_dir, f"{conversation_id}.json")
        full_data = {
            "conversation_id": conversation_id,
            "total_nodes": len(all_nodes),
            "last_updated": all_nodes[-1].timestamp.isoformat() if all_nodes else None,
            "nodes": [
                {
                    "node_id": node.node_id,
                    "node_type": node.node_type.value,
                    "content": node.content,
                    "summary": node.summary,
                    "timestamp": node.timestamp.isoformat(),
                    "sequence_number": node.sequence_number,
                    "line_count": node.line_count,
                    "compression_level": node.level.value,
                    "tokens_used": node.tokens_used,
                    "topics": node.topics
                    if node.topics and isinstance(node.topics, list)
                    else [],
                    "relates_to_node_id": node.relates_to_node_id,
                }
                for node in all_nodes
            ],
        }

        with open(conversation_json_path, "w", encoding="utf-8") as f:
            json.dump(full_data, f, indent=2, ensure_ascii=False)

        # Save AI view
        ai_view_json_path = os.path.join(export_dir, f"{conversation_id}_ai_view.json")
        ai_view_raw = manager.get_last_ai_view_data()

        if ai_view_raw:
            ai_view_data = {
                "conversation_id": conversation_id,
                "description": "This shows exactly what the AI agent saw in the last message processing",
                "last_updated": all_nodes[-1].timestamp.isoformat()
                if all_nodes
                else None,
                "compressed_nodes_count": len(ai_view_raw.get("compressed_nodes", [])),
                "recent_nodes_count": len(ai_view_raw.get("recent_nodes", [])),
                "recent_messages_from_input_count": len(
                    ai_view_raw.get("recent_messages_from_input", [])
                ),
                "total_messages_sent_to_ai": ai_view_raw.get(
                    "total_messages_sent_to_ai", 0
                ),
                "compressed_nodes": ai_view_raw.get("compressed_nodes", []),
                "recent_nodes": ai_view_raw.get("recent_nodes", []),
                "recent_messages_from_input": ai_view_raw.get(
                    "recent_messages_from_input", []
                ),
            }
        else:
            ai_view_data = {
                "conversation_id": conversation_id,
                "description": "No AI view data available yet - send a message to see what the AI sees",
                "last_updated": all_nodes[-1].timestamp.isoformat()
                if all_nodes
                else None,
                "note": "The AI view is captured during message processing.",
            }

        with open(ai_view_json_path, "w", encoding="utf-8") as f:
            json.dump(ai_view_data, f, indent=2, ensure_ascii=False)

    except Exception as e:
        logger.debug(f"Error saving conversation to JSON: {e}")


@app.command()
def chat(
    conversation_id: Optional[str] = typer.Option(
        None, "--conversation-id", "-c", help="Resume existing conversation"
    ),
    name: Optional[str] = typer.Option(
        None, "--name", "-n", help="Create or resume conversation by name"
    ),
    model: Optional[str] = typer.Option(None, "--model", "-m", help="LLM model to use"),
    db_path: Optional[str] = typer.Option(
        None, "--db-path", "-d", help="Database path"
    ),
    recent_limit: Optional[int] = typer.Option(
        None, "--recent-limit", "-r", help="Recent nodes limit"
    ),
    mcp_port: Optional[int] = typer.Option(
        None, "--mcp-port", help="MCP server port (default from config)"
    ),
    export_dir: str = typer.Option(
        ".conversations",
        "--export-dir",
        help="Directory for real-time conversation exports",
    ),
    stream: bool = typer.Option(
        True,
        "--stream/--no-stream",
        help="Enable streaming responses (default: True)",
    ),
    dangerously_skip_permissions: bool = typer.Option(
        False,
        "--dangerously-skip-permissions",
        help="Skip all permission prompts (use with caution)",
    ),
    agentic: bool = typer.Option(
        False,
        "--agentic",
        help="Agentic mode: AI continues autonomously until it yields to human or is interrupted",
    ),
):
    """Start an interactive chat session with MCP memory tools."""
    asyncio.run(
        _chat_session(
            conversation_id,
            name,
            model,
            db_path,
            recent_limit,
            mcp_port,
            export_dir,
            stream,
            dangerously_skip_permissions,
            agentic,
        )
    )


async def _chat_session(
    conversation_id: Optional[str],
    name: Optional[str],
    model: Optional[str],
    db_path: Optional[str],
    recent_limit: Optional[int],
    mcp_port: Optional[int],
    export_dir: str,
    stream: bool,
    dangerously_skip_permissions: bool = False,
    agentic: bool = False,
):
    """Run the interactive chat session with MCP integration."""
    # Load configuration
    config = Config.from_env()

    # Override with CLI arguments
    if model:
        config.work_model = model
    if db_path:
        config.db_path = db_path
    if recent_limit:
        config.recent_node_limit = recent_limit
    if mcp_port:
        config.mcp_port = mcp_port
    if dangerously_skip_permissions:
        config.agent_permission_mode = "bypassPermissions"

    # Configure test-specific settings
    config.recent_node_limit = config.recent_node_limit or 5
    config.summary_threshold = config.summary_threshold or 20

    # Check if using Claude Agent SDK
    is_agent_sdk = ModelManager.is_claude_agent_sdk_model(config.work_model)

    console.print("[bold green]ğŸš€ Hierarchical Memory Middleware[/bold green]")
    console.print(f"ğŸ“„ Database: {config.db_path}")
    console.print(f"ğŸ¤– Model: {config.work_model}")
    if is_agent_sdk:
        console.print("[cyan]ğŸ”Œ Provider: Claude Agent SDK (CLI auth)[/cyan]")
        console.print("[cyan]ğŸ§  Memory tools: Built-in (via stdio subprocess)[/cyan]")
    if dangerously_skip_permissions:
        console.print("[bold red]âš ï¸  DANGER: All permissions bypassed![/bold red]")
    if agentic:
        console.print(
            "[bold cyan]ğŸ¤– AGENTIC MODE: AI continues until done. Ctrl+C to interrupt, Ctrl+CÃ—2 to quit[/bold cyan]"
        )
    console.print(f"ğŸ”— Recent nodes limit: {config.recent_node_limit}")
    console.print(f"ğŸ“ˆ Summary threshold: {config.summary_threshold}")
    console.print(f"âš¡ Streaming: {'Enabled' if stream else 'Disabled'}")

    # Setup MCP server (only needed for non-Agent SDK models)
    mcp_server_url = None
    external_clients = []
    mcp_manager = SimpleMCPManager()

    if not is_agent_sdk:
        # For PydanticAI models, check if MCP server is running
        mcp_server_url = f"http://127.0.0.1:{config.mcp_port}/mcp"
        console.print(f"ğŸ“¡ MCP server: {mcp_server_url}")

        mcp_running = check_mcp_server_running(mcp_server_url)
        if mcp_running:
            console.print("[green]âœ… MCP server is running[/green]")
            # Load and start external MCP servers
            external_servers = config.load_external_mcp_servers()
            for server_name, server_config in external_servers.items():
                client = await mcp_manager.start_server(server_name, server_config)
                if client:
                    external_clients.append(client)
        else:
            console.print("[red]âŒ MCP server is not running![/red]")
            console.print("[yellow]Please start the MCP server first:[/yellow]")
            console.print(
                f"[yellow]   python -m hierarchical_memory_middleware.mcp_server.run_server[/yellow]"
            )
            sys.exit(1)

    console.print()

    # Setup conversation export directory
    os.makedirs(export_dir, exist_ok=True)

    try:
        # Initialize conversation manager (factory auto-selects based on model)
        manager = create_conversation_manager(
            config=config,
            mcp_server_url=mcp_server_url,
            external_mcp_servers=external_clients if external_clients else None,
            agentic_mode=agentic,
        )

        # Resolve conversation identifier
        resolved_conversation_id = None
        if conversation_id and name:
            console.print(
                "[red]âŒ Cannot specify both --conversation-id and --name[/red]"
            )
            sys.exit(1)
        elif conversation_id:
            # Use conversation ID (supports partial matching)
            try:
                resolved_conversation_id = await resolve_conversation_id(
                    conversation_id, config.db_path
                )
                console.print(
                    f"[dim]Resolved conversation ID: {resolved_conversation_id}[/dim]"
                )
            except ValueError as e:
                console.print(f"[red]âŒ {e}[/red]")
                sys.exit(1)
        elif name:
            # Use conversation name
            try:
                resolved_conversation_id = await resolve_conversation_name(
                    name, config.db_path
                )
                console.print(
                    f"[dim]Resolved conversation '{name}' to ID: {resolved_conversation_id}[/dim]"
                )
            except ValueError:
                # Name not found, will create new conversation with this name
                console.print(
                    f"[yellow]Creating new conversation with name '{name}'[/yellow]"
                )
                resolved_conversation_id = None

        # Start or resume conversation
        conv_id = await manager.start_conversation(resolved_conversation_id)

        # Set conversation name if specified and it's a new conversation
        if name and resolved_conversation_id is None:
            await manager.set_conversation_name(conv_id, name)
            console.print(f"[green]âœ… Named conversation '{name}' created[/green]")

        console.print(f"[blue]ğŸ”— Conversation ID: {conv_id}[/blue]")
        if name:
            console.print(f"[blue]ğŸ“ Conversation Name: {name}[/blue]")
        console.print()

        # Setup conversation JSON export paths
        conversation_json_path = os.path.join(export_dir, f"{conv_id}.json")
        conversation_ai_view_json_path = os.path.join(
            export_dir, f"{conv_id}_ai_view.json"
        )
        console.print(
            f"[dim]ğŸ“„ Real-time conversation JSON: {conversation_json_path}[/dim]"
        )
        console.print(f"[dim]ğŸ¤– AI view JSON: {conversation_ai_view_json_path}[/dim]")
        console.print()

        # Show conversation summary if resuming
        if conversation_id == conv_id:  # Successfully resumed
            await show_conversation_summary(manager)

        # Save initial conversation state
        await save_conversation_to_json(manager, conv_id, export_dir)

        # Show help
        console.print("[bold cyan]ğŸ’¬ Chat Commands:[/bold cyan]")
        console.print(
            "   [yellow]/search <query>[/yellow]      - Search conversation memory"
        )
        console.print(
            "   [yellow]/expand <node_id>[/yellow]    - Expand a node to see full content"
        )
        console.print(
            "   [yellow]/summary[/yellow]             - Show conversation summary"
        )
        console.print("   [yellow]/recent[/yellow]              - Show recent messages")
        console.print(
            "   [yellow]/summaries <start> <end>[/yellow] - Show hierarchical summaries (Phase 4)"
        )
        console.print(
            "   [yellow]/stats[/yellow]               - Show detailed statistics"
        )
        console.print(
            "   [yellow]/remove_node <node_id>[/yellow] - Remove a node (with confirmation)"
        )
        console.print("   [yellow]/help[/yellow]                - Show this help")
        console.print(
            "   [yellow]/quit[/yellow] or [yellow]/exit[/yellow]        - Exit chat"
        )
        console.print()

        # Main chat loop state
        yielded_to_human = True  # Start by waiting for user input
        interrupted = False

        # Setup signal handler for Ctrl+C in agentic mode
        def handle_sigint(signum, frame):
            nonlocal interrupted, yielded_to_human
            if agentic:
                interrupted = True
                yielded_to_human = True
                console.print(
                    "\n[yellow]â¸ï¸  Ctrl+C: Interrupting... (press again quickly to quit)[/yellow]"
                )
            else:
                raise KeyboardInterrupt()

        # Track rapid Ctrl+C for force quit
        last_sigint_time = [0.0]  # Use list to allow modification in closure
        original_handler = signal.getsignal(signal.SIGINT)

        def handle_sigint_with_force_quit(signum, frame):
            nonlocal interrupted, yielded_to_human
            current_time = time.time()
            # If Ctrl+C pressed twice within 1 second, force quit
            if current_time - last_sigint_time[0] < 1.0:
                console.print("\n[red]ğŸ‘‹ Force quit[/red]")
                sys.exit(0)
            last_sigint_time[0] = current_time

            if agentic:
                interrupted = True
                yielded_to_human = True
                console.print(
                    "\n[yellow]â¸ï¸  Interrupted - waiting for your input (Ctrl+C again to quit)[/yellow]"
                )
            else:
                console.print("\n[yellow]ğŸ‘‹ Chat interrupted by user[/yellow]")
                raise KeyboardInterrupt()

        signal.signal(signal.SIGINT, handle_sigint_with_force_quit)

        while True:
            try:
                # Debug: Log state at decision point
                logger.debug(f"DEBUG: Loop start - agentic={agentic}, yielded_to_human={yielded_to_human}, interrupted={interrupted}")

                # Determine if we should auto-continue or wait for human input
                if agentic and not yielded_to_human and not interrupted:
                    # Auto-continue mode - AI keeps working
                    user_input = "continue (auto-response)"
                    console.print("[dim]ğŸ”„ Auto-continuing...[/dim]")
                    logger.debug("DEBUG: Auto-continue triggered - yielded_to_human was False at decision point")
                else:
                    # Wait for human input
                    logger.debug(f"DEBUG: Waiting for human input (yielded_to_human={yielded_to_human})")
                    yielded_to_human = False  # Reset for next iteration
                    interrupted = False
                    try:
                        # Use robust input handler that handles multiline pastes
                        user_input, was_large_paste = handle_user_input(
                            conv_id, compact_large_pastes=True
                        )
                    except KeyboardInterrupt:
                        # Handle Ctrl+C/Ctrl+D during input prompt
                        console.print()  # New line after ^C
                        if agentic:
                            # Ensure we don't auto-continue after interrupt
                            yielded_to_human = True
                            continue
                        else:
                            break

                if not user_input:
                    continue

                # Handle special commands
                if user_input.startswith("/"):
                    await handle_chat_command(user_input, manager, conv_id, export_dir)
                    yielded_to_human = True  # After commands, wait for next user input
                    continue

                # Generate AI response
                if stream:
                    # Streaming mode
                    console.print("[bold green]ğŸ¤– Assistant:[/bold green]")
                    console.print(
                        "â”Œâ”€ [green]Response[/green] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
                    )

                    # Stream the response with tool events
                    response_chunks = []
                    is_agent_sdk = isinstance(
                        manager, ClaudeAgentSDKConversationManager
                    )
                    pending_tools = {}  # Track tool_id -> tool_name for matching results
                    stream_interrupted = False

                    # Use tool events only for Agent SDK manager
                    if is_agent_sdk:
                        stream_iter = manager.chat_stream(
                            user_input, include_tool_events=True
                        )
                    else:
                        stream_iter = manager.chat_stream(user_input)

                    try:
                        async for event in stream_iter:
                            # Check if we've been interrupted by signal handler
                            if interrupted:
                                stream_interrupted = True
                                break
                            if isinstance(event, str):
                                # Regular text chunk - escape Rich markup chars
                                console.print(rich_escape(event), end="", style="white")
                                response_chunks.append(event)
                            elif isinstance(event, ToolCallEvent):
                                # Track this tool call for later result matching
                                pending_tools[event.tool_id] = event.tool_name
                                logger.debug(f"DEBUG: ToolCallEvent received - tool_name={event.tool_name}")
                                # Check if this is a yield_to_human call
                                if event.tool_name == "mcp__memory__yield_to_human":
                                    yielded_to_human = True
                                    reason = event.tool_input.get(
                                        "reason", "Task complete"
                                    )
                                    console.print()
                                    console.print(
                                        f"  [bold yellow]â¸ï¸  Yielding to human: {rich_escape(reason)}[/bold yellow]"
                                    )
                                    logger.debug(f"DEBUG: yield_to_human detected, flag set to True")
                                else:
                                    # Display tool call with collapsible style
                                    console.print()
                                    console.print(
                                        f"  [cyan]â–¶ ğŸ”§ {event.tool_name}[/cyan]"
                                    )

                                    # Special formatting for Edit tool - show diff-style
                                    if event.tool_name == "Edit" and "old_string" in event.tool_input:
                                        diff_output = format_edit_diff(
                                            old_string=event.tool_input.get("old_string", ""),
                                            new_string=event.tool_input.get("new_string", ""),
                                            file_path=event.tool_input.get("file_path", "unknown"),
                                        )
                                        console.print(diff_output)
                                    else:
                                        # Default formatting for other tools
                                        tool_input_str = json.dumps(
                                            event.tool_input, indent=2
                                        )
                                        if len(tool_input_str) > 200:
                                            tool_input_preview = (
                                                tool_input_str[:200] + "..."
                                            )
                                        else:
                                            tool_input_preview = tool_input_str
                                        console.print(
                                            f"    [dim]{rich_escape(tool_input_preview)}[/dim]"
                                        )
                            elif isinstance(event, ToolResultEvent):
                                # Get tool name from pending calls
                                tool_name = pending_tools.get(event.tool_id, "unknown")
                                # Skip displaying yield_to_human results (already shown)
                                if tool_name == "mcp__memory__yield_to_human":
                                    continue
                                # Display tool result with tool name
                                result_preview = (
                                    event.content[:300]
                                    if len(event.content) > 300
                                    else event.content
                                )
                                # Truncate to first few lines
                                lines = result_preview.split("\n")
                                if len(lines) > 5:
                                    result_preview = (
                                        "\n".join(lines[:5])
                                        + f"\n    ... ({len(lines)} lines total)"
                                    )
                                style = "red" if event.is_error else "dim green"
                                console.print(
                                    f"  [cyan]â—€ {tool_name}:[/cyan] [{style}]{rich_escape(result_preview)}[/{style}]"
                                )
                                console.print()
                    except KeyboardInterrupt:
                        # Direct Ctrl+C during streaming
                        stream_interrupted = True
                    except SystemExit as e:
                        # Subprocess exit - check if SIGINT related
                        exit_code = e.code if hasattr(e, "code") else None
                        if exit_code in (-2, 130, 2) or interrupted:
                            stream_interrupted = True
                        else:
                            raise
                    except Exception as stream_error:
                        # Check if this was due to Ctrl+C interrupt
                        # Exit codes: -2 (Python internal), 130 (128+2, standard SIGINT)
                        error_str = str(stream_error).lower()
                        is_sigint = (
                            interrupted
                            or "exit code -2" in error_str
                            or "exit code 130" in error_str
                            or "exit code: -2" in error_str
                            or "exit code: 130" in error_str
                            or "sigint" in error_str
                        )
                        if is_sigint:
                            stream_interrupted = True
                            # Don't log this as an error - it's expected
                        else:
                            # Re-raise unexpected errors
                            raise

                    # Add bottom border
                    console.print()
                    if stream_interrupted:
                        console.print(
                            "â””â”€ [yellow]interrupted[/yellow] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
                        )
                    else:
                        console.print(
                            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
                        )
                    console.print()
                    response = "".join(response_chunks)

                    # If stream was interrupted, save partial response
                    if stream_interrupted:
                        console.print("[dim]ğŸ“ Saving partial response...[/dim]")
                        # Try to save the partial response to storage
                        try:
                            await manager.save_partial_response(response)
                            console.print("[dim]âœ“ Partial response saved[/dim]")
                        except AttributeError:
                            # Manager doesn't support save_partial_response (e.g., non-Agent SDK)
                            pass
                        except Exception as e:
                            logger.debug(f"Failed to save partial response: {e}")
                else:
                    # Non-streaming mode
                    console.print("[bold green]ğŸ¤– Thinking...[/bold green]")
                    response = await manager.chat(user_input)

                    # Display response in panel
                    console.print(
                        Panel(
                            Text(response, style="white"),
                            title="ğŸ¤– Assistant",
                            border_style="green",
                        )
                    )
                    console.print()
                    # In non-streaming mode, always yield after response
                    yielded_to_human = True

                # Save conversation state
                await save_conversation_to_json(manager, conv_id, export_dir)

                # Debug: Log flag state before decision
                logger.debug(f"DEBUG: After stream complete - agentic={agentic}, yielded_to_human={yielded_to_human}, interrupted={interrupted}")

                # If not in agentic mode, always wait for human input
                if not agentic:
                    yielded_to_human = True

            except KeyboardInterrupt:
                # Signal handler already printed message and set flags
                if not agentic:
                    break
                # In agentic mode, signal handler already set interrupted=True, yielded_to_human=True
                continue
            except SystemExit as e:
                # Handle subprocess exit codes (SIGINT = 130 or -2)
                exit_code = e.code if hasattr(e, "code") else None
                if exit_code in (-2, 130, 2) or interrupted:
                    # SIGINT-related exit - treat as interrupt in agentic mode
                    if agentic:
                        console.print(
                            "\n[yellow]â¸ï¸  Process interrupted - waiting for your input[/yellow]"
                        )
                        yielded_to_human = True
                        interrupted = False
                        continue
                    else:
                        break
                else:
                    # Non-SIGINT exit - re-raise
                    raise
            except Exception as e:
                # Check if this is a SIGINT-related error message
                error_str = str(e).lower()
                is_sigint = (
                    "exit code -2" in error_str
                    or "exit code 130" in error_str
                    or "exit code: -2" in error_str
                    or "exit code: 130" in error_str
                    or "sigint" in error_str
                )
                if is_sigint and agentic:
                    console.print(
                        "\n[yellow]â¸ï¸  Process interrupted - waiting for your input[/yellow]"
                    )
                    yielded_to_human = True
                    interrupted = False
                    continue
                elif is_sigint:
                    break
                console.print(f"[red]âŒ Error: {str(e)}[/red]")
                logger.exception("Chat error")
                yielded_to_human = True  # Wait for user after error
                continue

    except SystemExit as e:
        # Handle subprocess exit during cleanup
        exit_code = e.code if hasattr(e, "code") else None
        if exit_code not in (-2, 130, 2, 0, None):
            console.print(f"[red]âŒ Process exited with code {exit_code}[/red]")
        # Don't re-raise - just exit cleanly
    except Exception as e:
        console.print(f"[red]âŒ Failed to initialize: {str(e)}[/red]")
        logger.exception("Initialization error")
        sys.exit(1)
    finally:
        # Restore original signal handler
        if "original_handler" in dir():
            signal.signal(signal.SIGINT, original_handler)
        # Clean up external servers
        mcp_manager.stop_all()

    console.print("[blue]ğŸ‘‹ Goodbye![/blue]")


async def show_conversation_summary(manager):
    """Show conversation summary with rich formatting."""
    try:
        summary = await manager.get_conversation_summary()
        if "error" not in summary:
            # Get compression levels from the stats
            levels = summary.get('compression_levels', {})
            full_count = levels.get('full', 0)
            summary_count = levels.get('summary', 0)
            meta_count = levels.get('meta', 0)
            archive_count = levels.get('archive', 0)
            compressed_count = summary_count + meta_count + archive_count

            console.print(
                Panel(
                    f"ğŸ“Š Total nodes: {summary.get('total_nodes', 0)}\n"
                    f"ğŸ”„ Recent nodes (full): {full_count}\n"
                    f"ğŸ—œï¸ Compressed nodes: {compressed_count} (summary: {summary_count}, meta: {meta_count}, archive: {archive_count})",
                    title="ğŸ“‹ Conversation Summary",
                    border_style="blue",
                )
            )
        else:
            console.print(f"[red]âŒ Error getting summary: {summary['error']}[/red]")
    except Exception as e:
        console.print(f"[red]âŒ Error getting summary: {e}[/red]")


async def handle_chat_command(command: str, manager, conv_id: str, export_dir: str):
    """Handle special chat commands."""
    parts = command.split(" ", 1)
    cmd = parts[0].lower()
    args = parts[1] if len(parts) > 1 else ""

    if cmd in ["/quit", "/exit"]:
        console.print("[blue]ğŸ‘‹ Goodbye![/blue]")
        sys.exit(0)

    elif cmd == "/help":
        console.print("[bold cyan]ğŸ“š Available Commands:[/bold cyan]")
        console.print(
            "   [yellow]/search <query>[/yellow]      - Search conversation memory"
        )
        console.print(
            "   [yellow]/expand <node_id>[/yellow]    - Expand a node to see full content"
        )
        console.print(
            "   [yellow]/summary[/yellow]             - Show conversation summary"
        )
        console.print("   [yellow]/recent[/yellow]              - Show recent messages")
        console.print(
            "   [yellow]/summaries <start> <end>[/yellow] - Show hierarchical summaries (Phase 4)"
        )
        console.print(
            "   [yellow]/stats[/yellow]               - Show detailed statistics"
        )
        console.print(
            "   [yellow]/remove_node <node_id>[/yellow] - Remove a node (with confirmation)"
        )
        console.print(
            "   [yellow]/rename <new_name>[/yellow]        - Rename current conversation"
        )
        console.print(
            "   [yellow]/quit[/yellow], [yellow]/exit[/yellow]         - Exit chat"
        )

    elif cmd == "/search":
        if args:
            await search_memory(manager, args)
        else:
            console.print("[red]âŒ Usage: /search <query>[/red]")

    elif cmd == "/expand":
        if args:
            try:
                node_id = int(args)
                await expand_node(manager, node_id, conv_id)
            except ValueError:
                console.print("[red]âŒ Invalid node_id. Please provide a number.[/red]")
        else:
            console.print("[red]âŒ Usage: /expand <node_id>[/red]")

    elif cmd == "/summary":
        await show_conversation_summary(manager)

    elif cmd == "/recent":
        await show_recent_messages(manager)

    elif cmd == "/summaries":
        if args:
            try:
                parts = args.split()
                if len(parts) == 2:
                    start_node = int(parts[0])
                    end_node = int(parts[1])
                    await show_hierarchical_summaries(
                        manager, conv_id, start_node, end_node
                    )
                else:
                    console.print(
                        "[red]âŒ Usage: /summaries <start_node> <end_node>[/red]"
                    )
            except ValueError:
                console.print("[red]âŒ Invalid node IDs. Please provide numbers.[/red]")
        else:
            console.print("[red]âŒ Usage: /summaries <start_node> <end_node>[/red]")

    elif cmd == "/stats":
        await show_detailed_stats(manager)

    elif cmd == "/rename":
        if args:
            try:
                success = await manager.set_conversation_name(conv_id, args.strip())
                if success:
                    console.print(
                        f"[green]âœ… Conversation renamed to '{args.strip()}'[/green]"
                    )
                else:
                    console.print(
                        f"[red]âŒ Failed to rename conversation. Name '{args.strip()}' may already exist.[/red]"
                    )
            except Exception as e:
                console.print(f"[red]âŒ Error renaming conversation: {e}[/red]")
        else:
            console.print("[red]âŒ Usage: /rename <n>[/red]")

    elif cmd == "/remove_node":
        if args:
            try:
                node_id = int(args)
                await remove_node_from_chat(manager, node_id, conv_id)
            except ValueError:
                console.print("[red]âŒ Invalid node_id. Please provide a number.[/red]")
        else:
            console.print("[red]âŒ Usage: /remove_node <node_id>[/red]")

    else:
        console.print(
            f"[red]âŒ Unknown command: {cmd}. Type /help for available commands.[/red]"
        )

    console.print()


async def search_memory(manager, query: str):
    """Search conversation memory with rich formatting."""
    try:
        console.print(f"[cyan]ğŸ” Searching for: '{query}'[/cyan]")
        results = await manager.find(query, limit=10)

        if not results:
            console.print("[yellow]ğŸ“­ No results found.[/yellow]")
            return

        table = Table(title=f"ğŸ” Search Results for '{query}'", show_header=True)
        table.add_column("Node ID", style="cyan", width=8)
        table.add_column("Type", style="magenta", width=8)
        table.add_column("Content", style="white")
        table.add_column("Score", style="green", width=8)

        for result in results:
            node_type = result["node_type"]
            content = result.get("summary") or result["content"]
            score = result["relevance_score"]
            node_id = result.get("node_id", "unknown")

            # Truncate long content
            if len(content) > 100:
                content = content[:100] + "..."

            table.add_row(
                str(node_id),
                "ğŸ‘¤ User" if node_type == "user" else "ğŸ¤– AI",
                content,
                f"{score:.2f}",
            )

        console.print(table)

    except Exception as e:
        console.print(f"[red]âŒ Error searching: {e}[/red]")


async def expand_node(manager, node_id: int, conv_id: str):
    """Expand a node to show full content."""
    try:
        console.print(f"[cyan]ğŸ” Expanding node {node_id}...[/cyan]")
        result = await manager.get_node_details(node_id, conv_id)

        if result is None:
            console.print(
                f"[red]âŒ Node {node_id} not found in conversation {conv_id}[/red]"
            )
            return

        # Create detailed panel
        node_info = []
        node_info.append(f"**Type:** {result.get('node_type', 'unknown')}")
        node_info.append(f"**Timestamp:** {result.get('timestamp', 'unknown')}")
        node_info.append(f"**Sequence:** {result.get('sequence_number', 'unknown')}")
        node_info.append(f"**Compression Level:** {result.get('level', 'unknown')}")
        node_info.append(f"**Line Count:** {result.get('line_count', 'unknown')}")
        node_info.append(f"**Tokens Used:** {result.get('tokens_used', 'unknown')}")

        # Show topics if available
        topics = result.get("topics", [])
        if topics:
            node_info.append(f"**Topics:** {', '.join(topics)}")

        # Show summary if available
        summary = result.get("summary", "")
        if summary:
            node_info.append(f"**Summary:** {summary}")

        node_info.append("")
        node_info.append("**Content:**")
        node_info.append(result.get("content", ""))

        console.print(
            Panel(
                Markdown("\n".join(node_info)),
                title=f"ğŸ“„ Node {node_id} Details",
                border_style="blue",
                expand=False,
            )
        )

    except Exception as e:
        console.print(f"[red]âŒ Error expanding node {node_id}: {e}[/red]")


async def remove_node_from_chat(manager, node_id: int, conv_id: str):
    """Remove a node from the conversation with confirmation (for chat session)."""
    try:
        # Get node details first for confirmation
        node_details = await manager.get_node_details(node_id, conv_id)
        if not node_details:
            console.print(f"[red]âŒ Node {node_id} not found in conversation.[/red]")
            return

        # Show node details
        node_type_icon = "ğŸ‘¤" if node_details["node_type"] == "user" else "ğŸ¤–"
        content_preview = (
            node_details["content"][:100] + "..."
            if len(node_details["content"]) > 100
            else node_details["content"]
        )

        console.print(f"\n[yellow]ğŸ“„ Node {node_id} Details:[/yellow]")
        console.print(f"Type: {node_type_icon} {node_details['node_type']}")
        console.print(f"Timestamp: {node_details['timestamp']}")
        console.print(f"Level: {node_details['compression_level']}")
        console.print(f"Content Preview: {rich_escape(content_preview)}")

        # Ask for confirmation
        console.print(
            f"\n[red]âš ï¸  WARNING: This will permanently delete node {node_id} from the conversation.[/red]"
        )
        response = typer.prompt(
            "Are you sure you want to remove this node? (yes/no)", type=str
        )
        if response.lower() not in ["yes", "y"]:
            console.print("[yellow]Operation cancelled.[/yellow]")
            return

        # Remove the node
        success = await manager.remove_node(node_id, conv_id)

        if success:
            console.print(
                f"[green]âœ… Successfully removed node {node_id} from conversation.[/green]"
            )
        else:
            console.print(
                f"[red]âŒ Failed to remove node {node_id}. Node may not exist.[/red]"
            )

    except Exception as e:
        console.print(f"[red]âŒ Error removing node {node_id}: {e}[/red]")


async def show_recent_messages(manager, limit: int = 10):
    """Show recent conversation messages."""
    try:
        results = await manager.find("", limit=limit)
        if not results:
            console.print("[yellow]ğŸ“­ No recent messages found.[/yellow]")
            return

        table = Table(title="ğŸ“œ Recent Messages", show_header=True)
        table.add_column("#", style="dim", width=3)
        table.add_column("Node ID", style="cyan", width=8)
        table.add_column("Type", style="magenta", width=8)
        table.add_column("Time", style="blue", width=16)
        table.add_column("Content", style="white")

        for i, result in enumerate(results[:limit], 1):
            node_type = result["node_type"]
            content = result.get("summary") or result["content"]
            timestamp = result["timestamp"]
            node_id = result.get("node_id", "unknown")

            # Truncate long content
            if len(content) > 80:
                content = content[:80] + "..."

            table.add_row(
                str(i),
                str(node_id),
                "ğŸ‘¤ User" if node_type == "user" else "ğŸ¤– AI",
                timestamp[:16],
                content,
            )

        console.print(table)

    except Exception as e:
        console.print(f"[red]âŒ Error getting recent messages: {e}[/red]")


async def show_hierarchical_summaries(
    manager, conv_id: str, start_node: int, end_node: int
):
    """Show hierarchical summaries for a range of nodes (Phase 4 functionality)."""
    try:
        console.print(
            f"[bold cyan]ğŸ“Š Phase 4: Hierarchical Summaries for nodes {start_node}-{end_node}[/bold cyan]"
        )
        console.print("[dim]This demonstrates the advanced hierarchy system[/dim]")
        console.print()

        # Get nodes in range
        nodes = await manager.storage.get_nodes_in_range(
            conversation_id=conv_id,
            start_node_id=start_node,
            end_node_id=end_node,
        )

        if not nodes:
            console.print(
                f"[red]âŒ No nodes found in range {start_node}-{end_node}[/red]"
            )
            return

        # Group nodes by compression level
        nodes_by_level = {"FULL": [], "SUMMARY": [], "META": [], "ARCHIVE": []}

        for node in nodes:
            level_name = node.level.name
            nodes_by_level[level_name].append(node)

        # Display summary
        total_nodes = len(nodes)
        total_lines = sum(node.line_count or 0 for node in nodes)

        console.print(
            Panel(
                f"ğŸ“ˆ Found {total_nodes} nodes ({total_lines} total lines) in range {start_node}-{end_node}",
                title="ğŸ“‹ Range Summary",
                border_style="blue",
            )
        )

        # Show compression distribution
        compression_stats = {
            level: len(nodes) for level, nodes in nodes_by_level.items() if nodes
        }

        if compression_stats:
            table = Table(title="ğŸ—œï¸ Compression Distribution", show_header=True)
            table.add_column("Level", style="cyan")
            table.add_column("Count", style="green")
            table.add_column("Description", style="white")

            level_descriptions = {
                "FULL": "ğŸŸ¢ Recent nodes with complete content",
                "SUMMARY": "ğŸŸ¡ Older nodes with 1-2 sentence summaries",
                "META": "ğŸŸ  Groups of summary nodes (20-40 nodes each)",
                "ARCHIVE": "ğŸ”´ Very compressed high-level context",
            }

            for level, count in compression_stats.items():
                table.add_row(
                    level,
                    str(count),
                    level_descriptions.get(level, "Unknown level"),
                )

            console.print(table)

        # Show details for each level
        level_order = ["FULL", "SUMMARY", "META", "ARCHIVE"]
        for level in level_order:
            if level in nodes_by_level and nodes_by_level[level]:
                level_nodes = nodes_by_level[level]
                await show_level_details(level, level_nodes)

        # Show META group information
        meta_nodes = nodes_by_level.get("META", [])
        if meta_nodes:
            await show_meta_group_details(meta_nodes)

        console.print(
            "[bold green]âœ¨ This demonstrates Phase 4: Advanced Hierarchy with 4-level compression![/bold green]"
        )
        console.print("[dim]FULL â†’ SUMMARY â†’ META â†’ ARCHIVE[/dim]")

    except Exception as e:
        console.print(f"[red]âŒ Error showing hierarchical summaries: {e}[/red]")
        import traceback

        traceback.print_exc()


async def show_level_details(level: str, level_nodes):
    """Show details for a specific compression level."""
    level_descriptions = {
        "FULL": "ğŸŸ¢ Recent nodes with complete content",
        "SUMMARY": "ğŸŸ¡ Older nodes with 1-2 sentence summaries",
        "META": "ğŸŸ  Groups of summary nodes (20-40 nodes each)",
        "ARCHIVE": "ğŸ”´ Very compressed high-level context",
    }

    console.print(
        f"[bold]{level_descriptions[level]}[/bold] ({len(level_nodes)} nodes):"
    )

    for i, node in enumerate(level_nodes[:5], 1):  # Show first 5 nodes
        node_type_icon = "ğŸ‘¤" if node.node_type.value == "user" else "ğŸ¤–"

        # Determine content to show
        if node.summary:
            display_content = node.summary
            content_type = "[Summary]"
        else:
            display_content = node.content
            content_type = "[Full]"

        # Truncate long content
        if len(display_content) > 150:
            display_content = display_content[:150] + "..."

        console.print(
            f"   {i}. {node_type_icon} Node {node.node_id} {content_type}: {display_content}"
        )

    if len(level_nodes) > 5:
        console.print(f"   ... and {len(level_nodes) - 5} more nodes")
    console.print()


async def show_meta_group_details(meta_nodes):
    """Show details about META group nodes."""
    console.print("[bold]ğŸ”— META Group Details:[/bold]")

    for node in meta_nodes:
        if node.summary_metadata:
            try:
                metadata = json.loads(node.summary_metadata)
                meta_info = metadata.get("meta_group_info", {})
                if meta_info:
                    console.print(
                        f"   ğŸ“¦ Node {node.node_id}: Groups nodes {meta_info.get('start_node_id')}-{meta_info.get('end_node_id')}"
                    )
                    console.print(
                        f"      Topics: {', '.join(meta_info.get('main_topics', [])[:3])}"
                    )
                    console.print(
                        f"      Contains: {meta_info.get('node_count')} nodes, {meta_info.get('total_lines')} lines"
                    )
            except (json.JSONDecodeError, KeyError):
                console.print(
                    f"   ğŸ“¦ Node {node.node_id}: META group (details unavailable)"
                )
        else:
            console.print(f"   ğŸ“¦ Node {node.node_id}: META group (no metadata)")

    console.print()


async def show_detailed_stats(manager):
    """Show detailed conversation statistics."""
    try:
        summary = await manager.get_conversation_summary()
        if "error" in summary:
            console.print(f"[red]âŒ Error getting stats: {summary['error']}[/red]")
            return

        # Create comprehensive stats table
        table = Table(title="ğŸ“Š Detailed Conversation Statistics", show_header=True)
        table.add_column("Metric", style="cyan")
        table.add_column("Value", style="green")
        table.add_column("Description", style="white")

        table.add_row(
            "Total Nodes",
            str(summary.get("total_nodes", 0)),
            "Total conversation nodes in database",
        )
        table.add_row(
            "Recent Nodes",
            str(summary.get("recent_nodes", 0)),
            "Nodes at FULL compression level",
        )
        table.add_row(
            "Compressed Nodes",
            str(summary.get("compressed_nodes", 0)),
            "Nodes at SUMMARY/META/ARCHIVE levels",
        )

        # Add additional metrics if available
        if "compression_ratio" in summary:
            table.add_row(
                "Compression Ratio",
                f"{summary['compression_ratio']:.2%}",
                "Space saved through compression",
            )

        console.print(table)

    except Exception as e:
        console.print(f"[red]âŒ Error getting detailed stats: {e}[/red]")


# Add other commands from the original CLI


@app.command()
def summaries(
    conversation_id: str = typer.Argument(help="Conversation ID"),
    start_node: int = typer.Argument(help="Start node ID"),
    end_node: int = typer.Argument(help="End node ID"),
    db_path: Optional[str] = typer.Option(
        None, "--db-path", "-d", help="Database path"
    ),
    mcp_port: Optional[int] = typer.Option(None, "--mcp-port", help="MCP server port"),
):
    """Show hierarchical summaries for a range of nodes (Phase 4)."""
    asyncio.run(
        _show_summaries(conversation_id, start_node, end_node, db_path, mcp_port)
    )


async def _show_summaries(
    conversation_id: str,
    start_node: int,
    end_node: int,
    db_path: Optional[str],
    mcp_port: Optional[int],
):
    """Show hierarchical summaries implementation."""
    config = Config.from_env()
    if db_path:
        config.db_path = db_path
    if mcp_port:
        config.mcp_port = mcp_port

    try:
        conversation_id = await resolve_conversation_id(conversation_id, config.db_path)
        console.print(f"[dim]Resolved conversation ID: {conversation_id}[/dim]")
    except ValueError as e:
        console.print(f"[red]âŒ {e}[/red]")
        sys.exit(1)

    # Setup MCP
    mcp_server_url = f"http://127.0.0.1:{config.mcp_port}/mcp"
    if not check_mcp_server_running(mcp_server_url):
        console.print("[red]âŒ MCP server is not running![/red]")
        console.print("[yellow]Please start the MCP server first[/yellow]")
        sys.exit(1)

    try:
        manager = HierarchicalConversationManager(config, mcp_server_url=mcp_server_url)
        await manager.start_conversation(conversation_id)
        await show_hierarchical_summaries(
            manager, conversation_id, start_node, end_node
        )
    except Exception as e:
        console.print(f"[red]âŒ Error: {e}[/red]")


@app.command()
def expand(
    conversation_id: str = typer.Argument(help="Conversation ID"),
    node_id: int = typer.Argument(help="Node ID to expand"),
    db_path: Optional[str] = typer.Option(
        None, "--db-path", "-d", help="Database path"
    ),
    mcp_port: Optional[int] = typer.Option(None, "--mcp-port", help="MCP server port"),
):
    """Expand a node to show its full content."""
    asyncio.run(_expand_node(conversation_id, node_id, db_path, mcp_port))


async def _expand_node(
    conversation_id: str,
    node_id: int,
    db_path: Optional[str],
    mcp_port: Optional[int],
):
    """Expand node implementation."""
    config = Config.from_env()
    if db_path:
        config.db_path = db_path
    if mcp_port:
        config.mcp_port = mcp_port

    try:
        conversation_id = await resolve_conversation_id(conversation_id, config.db_path)
        console.print(f"[dim]Resolved conversation ID: {conversation_id}[/dim]")
    except ValueError as e:
        console.print(f"[red]âŒ {e}[/red]")
        sys.exit(1)

    # Setup MCP
    mcp_server_url = f"http://127.0.0.1:{config.mcp_port}/mcp"
    if not check_mcp_server_running(mcp_server_url):
        console.print("[red]âŒ MCP server is not running![/red]")
        sys.exit(1)

    try:
        manager = HierarchicalConversationManager(config, mcp_server_url=mcp_server_url)
        await manager.start_conversation(conversation_id)
        await expand_node(manager, node_id, conversation_id)
    except Exception as e:
        console.print(f"[red]âŒ Error: {e}[/red]")


@app.command()
def remove_node(
    conversation_id: str = typer.Argument(help="Conversation ID"),
    idx: int = typer.Argument(help="Node ID to remove"),
    db_path: Optional[str] = typer.Option(
        None, "--db-path", "-d", help="Database path"
    ),
    mcp_port: Optional[int] = typer.Option(None, "--mcp-port", help="MCP server port"),
    force: bool = typer.Option(False, "--force", "-f", help="Skip confirmation prompt"),
):
    """Remove a specific node from a conversation."""
    asyncio.run(_remove_node(conversation_id, idx, db_path, mcp_port, force))


async def _remove_node(
    conversation_id: str,
    node_id: int,
    db_path: Optional[str],
    mcp_port: Optional[int],
    force: bool,
):
    """Remove node implementation."""
    config = Config.from_env()
    if db_path:
        config.db_path = db_path
    if mcp_port:
        config.mcp_port = mcp_port

    try:
        # Resolve the conversation ID
        full_conversation_id = await resolve_conversation_identifier(
            conversation_id, config.db_path
        )

        # Initialize manager
        mcp_server_url = f"http://127.0.0.1:{config.mcp_port}/mcp"
        manager = HierarchicalConversationManager(config, mcp_server_url=mcp_server_url)

        # Get node details first for confirmation
        node_details = await manager.get_node_details(node_id, full_conversation_id)
        if not node_details:
            console.print(
                f"[red]âŒ Node {node_id} not found in conversation {full_conversation_id[:8]}...[/red]"
            )
            return

        # Show node details
        node_type_icon = "ğŸ‘¤" if node_details["node_type"] == "user" else "ğŸ¤–"
        content_preview = (
            node_details["content"][:100] + "..."
            if len(node_details["content"]) > 100
            else node_details["content"]
        )

        console.print(f"\n[yellow]ğŸ“„ Node {node_id} Details:[/yellow]")
        console.print(f"Type: {node_type_icon} {node_details['node_type']}")
        console.print(f"Timestamp: {node_details['timestamp']}")
        console.print(f"Level: {node_details['compression_level']}")
        console.print(f"Content Preview: {rich_escape(content_preview)}")

        # Confirmation unless --force is used
        if not force:
            console.print(
                f"\n[red]âš ï¸  WARNING: This will permanently delete node {node_id} from the conversation.[/red]"
            )
            response = typer.prompt(
                "Are you sure you want to remove this node? (yes/no)", type=str
            )
            if response.lower() not in ["yes", "y"]:
                console.print("[yellow]Operation cancelled.[/yellow]")
                return

        # Remove the node
        success = await manager.remove_node(node_id, full_conversation_id)

        if success:
            console.print(
                f"[green]âœ… Successfully removed node {node_id} from conversation {full_conversation_id[:8]}...[/green]"
            )
        else:
            console.print(
                f"[red]âŒ Failed to remove node {node_id}. Node may not exist.[/red]"
            )

    except Exception as e:
        console.print(f"[red]âŒ Error: {e}[/red]")


@app.command()
def search(
    query: str = typer.Argument(help="Search query"),
    conversation_id: Optional[str] = typer.Option(
        None, "--conversation-id", "-c", help="Limit search to specific conversation"
    ),
    limit: int = typer.Option(10, "--limit", "-l", help="Maximum number of results"),
    db_path: Optional[str] = typer.Option(
        None, "--db-path", "-d", help="Database path"
    ),
    mcp_port: Optional[int] = typer.Option(None, "--mcp-port", help="MCP server port"),
):
    """Search conversation memory across all conversations."""
    asyncio.run(_search_memory(query, conversation_id, limit, db_path, mcp_port))


async def _search_memory(
    query: str,
    conversation_id: Optional[str],
    limit: int,
    db_path: Optional[str],
    mcp_port: Optional[int],
):
    """Search memory implementation."""
    config = Config.from_env()
    if db_path:
        config.db_path = db_path
    if mcp_port:
        config.mcp_port = mcp_port

    if conversation_id:
        try:
            conversation_id = await resolve_conversation_id(
                conversation_id, config.db_path
            )
            console.print(f"[dim]Resolved conversation ID: {conversation_id}[/dim]")
        except ValueError as e:
            console.print(f"[red]âŒ {e}[/red]")
            sys.exit(1)

    mcp_server_url = f"http://127.0.0.1:{config.mcp_port}/mcp"
    if not check_mcp_server_running(mcp_server_url):
        console.print("[red]âŒ MCP server is not running![/red]")
        sys.exit(1)

    try:
        manager = HierarchicalConversationManager(config, mcp_server_url=mcp_server_url)
        if conversation_id:
            await manager.start_conversation(conversation_id)
        await search_memory(manager, query)
    except Exception as e:
        console.print(f"[red]âŒ Error: {e}[/red]")


@app.command()
def list_conversations(
    db_path: Optional[str] = typer.Option(
        None, "--db-path", "-d", help="Database path"
    ),
):
    """List all conversations in the database."""
    asyncio.run(_list_conversations(db_path))


async def _list_conversations(db_path: Optional[str]):
    """List conversations implementation."""
    config = Config.from_env()
    if db_path:
        config.db_path = db_path

    try:
        from .storage import DuckDBStorage

        storage = DuckDBStorage(config.db_path)

        # Get conversation list
        conversations = await storage.get_conversation_list()

        if not conversations:
            console.print("[yellow]ğŸ“­ No conversations found.[/yellow]")
            return

        table = Table(title="ğŸ“‹ Conversations", show_header=True)
        table.add_column("ID", style="cyan")
        table.add_column("Name", style="white")
        table.add_column("Created", style="blue")
        table.add_column("Last Updated", style="green")
        table.add_column("Nodes", style="yellow")
        table.add_column("Status", style="magenta")

        for conv in conversations:
            table.add_row(
                conv["id"][:8] + "...",
                conv.get("name", "<unnamed>"),
                conv["created"][:16] if conv["created"] else "Unknown",
                conv["last_updated"][:16] if conv["last_updated"] else "Unknown",
                str(conv["node_count"]),
                "Active" if conv["is_active"] else "Inactive",
            )

        console.print(table)

    except Exception as e:
        console.print(f"[red]âŒ Error: {e}[/red]")


@app.command()
def switch_conversation(
    identifier: str = typer.Argument(help="Conversation ID, partial ID, or name"),
    db_path: Optional[str] = typer.Option(
        None, "--db-path", "-d", help="Database path"
    ),
    mcp_port: Optional[int] = typer.Option(None, "--mcp-port", help="MCP server port"),
):
    """Switch to a conversation by ID, partial ID, or name and start chat session."""
    asyncio.run(_switch_conversation(identifier, db_path, mcp_port))


async def _switch_conversation(
    identifier: str,
    db_path: Optional[str],
    mcp_port: Optional[int],
):
    """Switch conversation implementation."""
    config = Config.from_env()
    if db_path:
        config.db_path = db_path
    if mcp_port:
        config.mcp_port = mcp_port

    try:
        conversation_id = await resolve_conversation_identifier(
            identifier, config.db_path
        )
        console.print(f"[green]âœ… Switching to conversation: {conversation_id}[/green]")

        # Start chat session with resolved conversation
        await _chat_session(
            conversation_id,
            None,
            None,
            config.db_path,
            None,
            mcp_port,
            ".conversations",
            True,  # Enable streaming by default
            False,  # dangerously_skip_permissions
            False,  # agentic mode
        )
    except ValueError as e:
        console.print(f"[red]âŒ {e}[/red]")

        # Show available conversations
        console.print("\n[yellow]Available conversations:[/yellow]")
        await _list_conversations(config.db_path)


@app.command()
def export_conversation(
    conversation_id: str = typer.Argument(help="Conversation ID to export"),
    output_file: Optional[str] = typer.Option(
        None, "--output", "-o", help="Output file (JSON)"
    ),
    db_path: Optional[str] = typer.Option(
        None, "--db-path", "-d", help="Database path"
    ),
    mcp_port: Optional[int] = typer.Option(None, "--mcp-port", help="MCP server port"),
):
    """Export a conversation to JSON."""
    asyncio.run(_export_conversation(conversation_id, output_file, db_path, mcp_port))


async def _export_conversation(
    conversation_id: str,
    output_file: Optional[str],
    db_path: Optional[str],
    mcp_port: Optional[int],
):
    """Export conversation implementation."""
    config = Config.from_env()
    if db_path:
        config.db_path = db_path
    if mcp_port:
        config.mcp_port = mcp_port

    # Resolve partial conversation ID
    try:
        conversation_id = await resolve_conversation_id(conversation_id, config.db_path)
        console.print(f"[dim]Resolved conversation ID: {conversation_id}[/dim]")
    except ValueError as e:
        console.print(f"[red]âŒ {e}[/red]")
        sys.exit(1)

    # Setup MCP
    mcp_server_url = f"http://127.0.0.1:{config.mcp_port}/mcp"
    if not check_mcp_server_running(mcp_server_url):
        console.print("[red]âŒ MCP server is not running![/red]")
        sys.exit(1)

    try:
        manager = HierarchicalConversationManager(config, mcp_server_url=mcp_server_url)
        await manager.start_conversation(conversation_id)

        summary = await manager.get_conversation_summary()

        if "error" in summary:
            console.print(f"[red]âŒ Error: {summary['error']}[/red]")
            return

        # Export data
        export_data = {
            "conversation_id": conversation_id,
            "summary": summary,
            "exported_at": datetime.now().isoformat(),
        }

        if output_file:
            with open(output_file, "w") as f:
                json.dump(export_data, f, indent=2)
            console.print(f"[green]âœ… Exported to {output_file}[/green]")
        else:
            console.print(json.dumps(export_data, indent=2))

    except Exception as e:
        console.print(f"[red]âŒ Error: {e}[/red]")


@app.command()
def server(
    action: str = typer.Argument(help="Action: start, stop, status"),
    port: Optional[int] = typer.Option(None, "--port", "-p", help="MCP server port"),
):
    """Manage MCP server."""
    config = Config.from_env()
    if port:
        config.mcp_port = port

    mcp_server_url = f"http://127.0.0.1:{config.mcp_port}/mcp"

    if action == "status":
        if check_mcp_server_running(mcp_server_url):
            console.print(
                f"[green]âœ… MCP server is running on port {config.mcp_port}[/green]"
            )
        else:
            console.print(
                f"[red]âŒ MCP server is not running on port {config.mcp_port}[/red]"
            )

    elif action == "start":
        console.print(
            f"[yellow]ğŸš€ Starting MCP server on port {config.mcp_port}...[/yellow]"
        )
        console.print(
            f"[dim]Run: python -m hierarchical_memory_middleware.mcp_server.run_server[/dim]"
        )
        console.print(
            f"[yellow]Note: This command shows you how to start the server manually.[/yellow]"
        )

    elif action == "stop":
        console.print(
            f"[yellow]ğŸ›‘ To stop the MCP server, use Ctrl+C in the server terminal[/yellow]"
        )

    else:
        console.print(
            f"[red]âŒ Unknown action: {action}. Use: start, stop, status[/red]"
        )


@app.command()
def version():
    """Show version information."""
    try:
        from . import __version__

        console.print(
            f"[bold green]Hierarchical Memory Middleware v{__version__}[/bold green]"
        )
    except ImportError:
        console.print("[bold green]Hierarchical Memory Middleware[/bold green]")
        console.print("[dim]Version information not available[/dim]")


def main():
    """Main CLI entry point."""
    app()


if __name__ == "__main__":
    main()
